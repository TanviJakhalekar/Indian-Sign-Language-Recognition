# Indian-Sign-Language-Recognition
The method of identifying and interpreting people's continuous hand motions in sign language is known as continuous sign language gesture recognition. Indian Sign Language (ISL) is a sign language used by those who are deaf and unable to speak or hear to communicate with others. The majority of individuals have trouble understanding ISL gestures. As a result, there is now a communication barrier between individuals who comprehend ISL and those who do not. When necessary, it can be difficult to locate an interpreter who can translate these signals. A potential method was built to translate hand positions and gestures from ISL in real-time in order to improve communication. It entails the use of computer vision, machine learning, and natural language processing strategies to analyze data from a variety of sources, including video recordings. A well-liked deep learning method for recognizing sign language gestures is Convolutional Neural Networks (CNN). It takes the use of computer vision, machine learning, and natural language processing techniques to recognize continuous sign language gestures accurately and effectively. These methods entail collecting and processing information from a variety of sources, video recordings of sign language gestures. In this project, our primary goal is to create a model that can recognize some fundamental hand gestures used in Indian Sign Language.

